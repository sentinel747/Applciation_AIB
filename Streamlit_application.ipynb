{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: newspaper3k in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (0.2.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (4.12.3)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (6.0.2)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (5.3.0)\n",
      "Requirement already satisfied: nltk>=3.2.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (3.9.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (2.32.3)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (6.0.11)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (5.1.2)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (2.9.0)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.6)\n",
      "Requirement already satisfied: six in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2024.7.4)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (2.1.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.13.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from click->nltk>=3.2.1->newspaper3k) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-search-results in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from google-search-results) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests->google-search-results) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests->google-search-results) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests->google-search-results) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: googletrans in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from googletrans) (0.13.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from httpx==0.13.3->googletrans) (2024.7.4)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from httpx==0.13.3->googletrans) (2024.10.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from httpx==0.13.3->googletrans) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-cpp-python in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (0.2.89+cpuavx2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from llama-cpp-python) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: googlesearch-python in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from googlesearch-python) (4.12.3)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from googlesearch-python) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests>=2.20->googlesearch-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests>=2.20->googlesearch-python) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests>=2.20->googlesearch-python) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from requests>=2.20->googlesearch-python) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (0.13.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\andrea\\text-generation-webui-main\\installer_files\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install pandas openpyxl\n",
    "%pip install transformers\n",
    "%pip install newspaper3k\n",
    "%pip install google-search-results\n",
    "%pip install googletrans\n",
    "%pip install llama-cpp-python\n",
    "%pip install tqdm\n",
    "%pip install googlesearch-python\n",
    "%pip install seaborn\n",
    "import pandas as pd\n",
    "df_data = pd.read_excel(r\"C:\\Users\\Andrea\\OneDrive - UNIVERSITA' CARLO CATTANEO - LIUC\\Desktop\\Magistrale\\Artificial Intelligence\\02 - Dataset\\Data Input - CRM Exraction.xlsx\")\n",
    "df_context = pd.read_excel(r\"C:\\Users\\Andrea\\OneDrive - UNIVERSITA' CARLO CATTANEO - LIUC\\Desktop\\Magistrale\\Artificial Intelligence\\02 - Dataset\\Context Input - Categories.xlsx\")\n",
    "# Imposto le opzioni per mostrare tutte le righe e colonne\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Importa tqdm per la barra di avanzamento\n",
    "\n",
    "# Rimozione delle colonne inutili\n",
    "df_data_cleaned = df_data.drop(columns=[\"Contact Name\", \"Contact Job Title\"])\n",
    "\n",
    "# Rimozione di duplicati e valori mancanti\n",
    "df_data_cleaned = df_data_cleaned.drop_duplicates()\n",
    "df_data_cleaned = df_data_cleaned.dropna()\n",
    "\n",
    "# Estrazione del dominio dall'email\n",
    "tqdm.pandas(desc=\"Estrazione domini\")\n",
    "df_data_cleaned['Email Domain'] = df_data_cleaned['Contact E-mail'].progress_apply(lambda email: email.split('@')[-1])\n",
    "\n",
    "# Rimozione dei domini pubblici\n",
    "public_domains = ['gmail.com', 'hotmail.com', 'yahoo.com', 'outlook.com', 'live.com', 'icloud.com', 'unknown.com']\n",
    "df_data_cleaned = df_data_cleaned[~df_data_cleaned['Email Domain'].isin(public_domains)]\n",
    "\n",
    "# Verifica dell'esistenza dei domini\n",
    "def check_domain_exists(domain):\n",
    "    try:\n",
    "        response = requests.get(f\"http://{domain}\", timeout=2)\n",
    "        return response.status_code == 200\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "tqdm.pandas(desc=\"Verifica dei domini\")\n",
    "df_data_cleaned['Domain Exists'] = df_data_cleaned['Email Domain'].progress_apply(check_domain_exists)\n",
    "df_data_cleaned = df_data_cleaned[df_data_cleaned['Domain Exists']]\n",
    "df_data_cleaned = df_data_cleaned.drop(columns=['Domain Exists'])  # Rimuove la colonna temporanea\n",
    "\n",
    "# Estrazione del nome principale del dominio (ad es., \"savills\" da \"savills.es\" e \"savills.pt\")\n",
    "df_data_cleaned['Main Domain Name'] = df_data_cleaned['Email Domain'].apply(lambda domain: domain.split('.')[0])\n",
    "\n",
    "# Rimozione dei duplicati basati sul nome principale del dominio mantenendo la prima occorrenza del dominio completo\n",
    "df_data_cleaned = df_data_cleaned.drop_duplicates(subset=[\"Main Domain Name\"])\n",
    "\n",
    "# Rimozione della colonna temporanea \"Main Domain Name\"\n",
    "df_data_cleaned = df_data_cleaned.drop(columns=['Main Domain Name'])\n",
    "\n",
    "# Rimozione dei duplicati finali su \"Contact E-mail\" e \"Email Domain\"\n",
    "df_data_cleaned = df_data_cleaned.drop_duplicates(subset=[\"Contact E-mail\"])\n",
    "df_data_cleaned = df_data_cleaned.drop_duplicates(subset=[\"Email Domain\"])\n",
    "\n",
    "# Salvataggio del risultato finale\n",
    "df_data_cleaned.to_excel(r'C:\\Users\\Andrea\\Downloads\\df_data_cleaned.xlsx', index=False)\n",
    "\n",
    "df_data_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Funzione per pulire il dataset delle categorie\n",
    "def clean_categories(df):\n",
    "    # Rimuovi duplicati e valori nulli\n",
    "    df_cleaned = df.drop_duplicates().dropna()\n",
    "\n",
    "    # Rimuovi le colonne specificate\n",
    "    df_cleaned = df_cleaned.drop(columns=['Can they buy the solution?', 'Can they influence the buying decision?'])\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# Applica la funzione di pulizia ai dati delle categorie\n",
    "df_context_cleaned = clean_categories(df_context)\n",
    "df_context_cleaned.to_excel(r'C:\\Users\\Andrea\\Downloads\\df_context_cleaned.xlsx', index=False)\n",
    "df_context_cleaned.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup # type: ignore\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Importa tqdm per la barra di avanzamento\n",
    "from transformers import pipeline\n",
    "\n",
    "# Inizializzazione del modello di Hugging Face per la traduzione\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-mul-en\")  # Modello per tradurre in inglese\n",
    "\n",
    "# Funzione per rimuovere duplicati da una lista di stringhe\n",
    "def remove_duplicates(description_parts):\n",
    "    seen = set()\n",
    "    unique_parts = []\n",
    "    for part in description_parts:\n",
    "        if part not in seen:\n",
    "            unique_parts.append(part)\n",
    "            seen.add(part)\n",
    "    return unique_parts\n",
    "\n",
    "# Funzione migliorata per estrarre più informazioni dai meta tag e dai paragrafi <p>\n",
    "def extract_meta_information(soup):\n",
    "    info = {}\n",
    "\n",
    "    # Estrarre meta description\n",
    "    description = soup.find('meta', attrs={'name': 'description'})\n",
    "    if description:\n",
    "        info['meta_description'] = description.get('content', '')\n",
    "\n",
    "    # Estrarre og:description (usato spesso per social e anteprime)\n",
    "    og_description = soup.find('meta', attrs={'property': 'og:description'})\n",
    "    if og_description:\n",
    "        info['og_description'] = og_description.get('content', '')\n",
    "\n",
    "    # Estrarre meta keywords (se disponibili)\n",
    "    keywords = soup.find('meta', attrs={'name': 'keywords'})\n",
    "    if keywords:\n",
    "        info['meta_keywords'] = keywords.get('content', '')\n",
    "\n",
    "    # Estrarre og:title (utilizzato per anteprime sui social)\n",
    "    og_title = soup.find('meta', attrs={'property': 'og:title'})\n",
    "    if og_title:\n",
    "        info['og_title'] = og_title.get('content', '')\n",
    "\n",
    "    # Estrazione di più paragrafi per raccogliere maggiori informazioni\n",
    "    paragraphs = soup.find_all('p')\n",
    "    if paragraphs:\n",
    "        # Limitiamo l'estrazione a un massimo di 7 paragrafi, per evitare di estrarre troppo testo\n",
    "        paragraph_text = \" \".join([p.get_text().strip() for p in paragraphs[:7] if p.get_text().strip()])\n",
    "        info['paragraphs'] = paragraph_text\n",
    "\n",
    "    return info\n",
    "\n",
    "# Funzione per estrarre informazioni dal sito web\n",
    "def extract_company_info(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Usa la funzione migliorata per estrarre le informazioni\n",
    "            meta_info = extract_meta_information(soup)\n",
    "\n",
    "            # Combina le informazioni raccolte per creare una descrizione\n",
    "            description_parts = []\n",
    "\n",
    "            # Aggiungi le varie descrizioni disponibili\n",
    "            if 'meta_description' in meta_info:\n",
    "                description_parts.append(meta_info['meta_description'])\n",
    "            if 'og_description' in meta_info:\n",
    "                description_parts.append(meta_info['og_description'])\n",
    "            if 'paragraphs' in meta_info:\n",
    "                description_parts.append(meta_info['paragraphs'])\n",
    "\n",
    "            # Rimuovi duplicati dalle descrizioni\n",
    "            unique_description_parts = remove_duplicates(description_parts)\n",
    "\n",
    "            # Unisci le parti di descrizione\n",
    "            full_description = \" \".join(unique_description_parts)\n",
    "            return full_description[:500]  # Limita a 500 caratteri\n",
    "        else:\n",
    "            return \"Company information not available.\"\n",
    "    except Exception as e:\n",
    "        return \"Company information not available.\"\n",
    "\n",
    "# Funzione per tradurre la descrizione in inglese\n",
    "def translate_to_english(text):\n",
    "    try:\n",
    "        translation = translator(text, max_length=500)\n",
    "        return translation[0]['translation_text']\n",
    "    except Exception as e:\n",
    "        return text\n",
    "\n",
    "# Funzione per creare il link del sito web a partire dal dominio email\n",
    "def construct_website_url(domain):\n",
    "    return f\"http://{domain}\"\n",
    "\n",
    "# Funzione per aggiungere la colonna \"Description\" nel DataFrame con barra di progresso\n",
    "def add_description_column(df):\n",
    "    descriptions = []\n",
    "    \n",
    "    # Usa tqdm per visualizzare la barra di avanzamento\n",
    "    for domain in tqdm(df['Email Domain'], desc=\"Estrazione informazioni\", unit=\"azienda\"):\n",
    "        website_url = construct_website_url(domain)\n",
    "        web_description = extract_company_info(website_url)\n",
    "        translated_description = translate_to_english(web_description)\n",
    "        descriptions.append(translated_description)\n",
    "\n",
    "    df['Description'] = descriptions  # Aggiungi tutte le descrizioni al DataFrame\n",
    "    return df\n",
    "\n",
    "# Esegui la funzione per aggiungere la colonna 'Description' al DataFrame esistente\n",
    "df_data_with_description = add_description_column(df_data_cleaned)\n",
    "df_data_with_description.to_excel(r'C:\\Users\\Andrea\\Downloads\\df_data_with_company_description.xlsx', index=False)\n",
    "\n",
    "df_data_with_description.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Funzione per eseguire la classificazione basata su TF-IDF e similarità coseno\n",
    "def classify_with_cosine_similarity(df_data, df_context):\n",
    "    # Combina le descrizioni e le note per costruire il vocabolario\n",
    "    all_texts = df_data['Description'].tolist() + df_context['Notes'].tolist()\n",
    "\n",
    "    # Creazione della rappresentazione TF-IDF per le descrizioni e le note\n",
    "    vectorizer = TfidfVectorizer().fit(all_texts)\n",
    "    company_vectors = vectorizer.transform(df_data['Description'])\n",
    "    category_vectors = vectorizer.transform(df_context['Notes'])\n",
    "\n",
    "    best_matches = []\n",
    "    similarities_matrix = []\n",
    "\n",
    "    # Calcola la similarità coseno tra ogni descrizione aziendale e le note delle categorie\n",
    "    for i in tqdm(range(company_vectors.shape[0]), desc=\"Classificazione\", unit=\"azienda\"):\n",
    "        similarities = cosine_similarity(company_vectors[i], category_vectors)\n",
    "        similarities_matrix.append(similarities.flatten())  # Appiattisci la matrice delle similarità\n",
    "        best_match_idx = similarities.argmax()  # Trova l'indice con la similarità massima\n",
    "        best_category = df_context.iloc[best_match_idx]['Player']  # Ottieni la categoria corrispondente\n",
    "        best_matches.append(best_category)\n",
    "\n",
    "    # Assegna la migliore categoria trovata al DataFrame\n",
    "    df_data['Best Category'] = best_matches\n",
    "    return df_data, pd.DataFrame(similarities_matrix)\n",
    "\n",
    "# Funzione per aggiungere la colonna \"Best Category\" e \"Is Target\" nel DataFrame\n",
    "def add_classification_and_target_column(df_data, df_context):\n",
    "    # Applica la classificazione basata su similarità coseno e ottieni la matrice di similarità\n",
    "    df_data, similarities_matrix = classify_with_cosine_similarity(df_data, df_context)\n",
    "\n",
    "    # Creazione della mappa per \"Is Target\"\n",
    "    target_map = df_context.set_index('Player')['Is Target'].to_dict()\n",
    "\n",
    "    # Funzione per verificare se la categoria è un target\n",
    "    def is_target_category(category):\n",
    "        return target_map.get(category, \"No\")  # Restituisce \"No\" se la categoria non è trovata\n",
    "\n",
    "    # Aggiunge la colonna \"Is Target\" in base alla categoria assegnata\n",
    "    df_data['Is Target'] = df_data['Best Category'].apply(lambda category: is_target_category(category))\n",
    "\n",
    "    return df_data, similarities_matrix\n",
    "\n",
    "# Funzione per visualizzare la distribuzione delle categorie (Target vs Non-Target)\n",
    "def plot_target_distribution(df_data):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.countplot(x='Is Target', data=df_data)\n",
    "    \n",
    "    # Aggiungi le etichette sopra ogni barra\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='baseline', fontsize=12, color='black', xytext=(0, 5),\n",
    "                    textcoords='offset points')\n",
    "\n",
    "    plt.title('Distribuzione delle Aziende tra Target e Non-Target')\n",
    "    plt.show()\n",
    "\n",
    "# Funzione per visualizzare la distribuzione delle categorie (Player)\n",
    "def plot_player_distribution(df_data):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.countplot(y='Best Category', data=df_data, order=df_data['Best Category'].value_counts().index)\n",
    "    \n",
    "    # Aggiungi le etichette per il numero di aziende per ciascuna categoria\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{int(p.get_width())}', (p.get_width(), p.get_y() + p.get_height() / 2),\n",
    "                    ha='center', va='baseline', fontsize=12, color='black', xytext=(0, 5),\n",
    "                    textcoords='offset points')\n",
    "\n",
    "    plt.title('Distribuzione delle Aziende per Categoria (Player)')\n",
    "    plt.show()\n",
    "\n",
    "# Funzione per visualizzare la heatmap delle similarità coseno\n",
    "def plot_similarity_heatmap(similarities_matrix):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(similarities_matrix, cmap=\"YlGnBu\", xticklabels=False, yticklabels=False)\n",
    "    plt.title(\"Heatmap delle Similarità Coseno tra Aziende e Categorie\")\n",
    "    plt.show()\n",
    "\n",
    "# Funzione per visualizzare un istogramma della distribuzione delle similarità\n",
    "def plot_similarity_histogram(similarities_matrix):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(similarities_matrix.to_numpy().flatten(), bins=20, kde=True)  # Conversione in NumPy array\n",
    "    plt.title(\"Distribuzione delle Similarità Coseno tra Aziende e Categorie\")\n",
    "    plt.xlabel(\"Valori di Similarità Coseno\")\n",
    "    plt.ylabel(\"Frequenza\")\n",
    "    plt.show()\n",
    "\n",
    "# Funzione per visualizzare la percentuale di target\n",
    "def plot_target_percentage(df_data):\n",
    "    target_counts = df_data['Is Target'].value_counts(normalize=True) * 100\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pie(target_counts, labels=target_counts.index, autopct='%1.1f%%', startangle=140, colors=['#ff9999','#66b3ff'])\n",
    "    plt.title(\"Percentuale di Aziende Target vs Non-Target\")\n",
    "    plt.show()\n",
    "\n",
    "# Applica la classificazione e la verifica del target utilizzando la similarità coseno\n",
    "df_data_classified_cosinesimilarity, similarities_matrix_cosinesimilarity = add_classification_and_target_column(df_data_with_description, df_context_cleaned)\n",
    "\n",
    "# Salva il DataFrame aggiornato con le categorie classificate e la colonna Is Target\n",
    "output_path_llm = r'C:\\Users\\Andrea\\Downloads\\data_classified_cosinesimilarity.xlsx'\n",
    "df_data_classified_cosinesimilarity.to_excel(output_path_llm, index=False)\n",
    "\n",
    "# Visualizza i grafici\n",
    "plot_target_distribution(df_data_classified_cosinesimilarity)\n",
    "plot_target_percentage(df_data_classified_cosinesimilarity)  # Aggiunta del grafico per la percentuale di Target\n",
    "plot_player_distribution(df_data_classified_cosinesimilarity)\n",
    "plot_similarity_heatmap(similarities_matrix_cosinesimilarity)\n",
    "plot_similarity_histogram(similarities_matrix_cosinesimilarity)\n",
    "\n",
    "df_data_classified_cosinesimilarity\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
